{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational EM for Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>References</strong>\n",
    "<ol>\n",
    "    <li><a href=http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf>Blei, Ng, & Jordan (2003)</a></li>\n",
    "    <li><a href=https://gytcrt.github.io/2016/05/02/topic-modeling-with-latent-dirichlet-allocation/>Topic Modeling with Latent Dirichlet Allocation (Gao & Liang)</a></li>\n",
    "</ol>\n",
    "Skip to the <a href=#Code>code</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "- $W$: Observed data\n",
    "- $D$: The total number of documents\n",
    "- $N_d$: The number of words in document $d$\n",
    "- $N$: The total number of unique words across all documents\n",
    "- $T$: The total number of topics \n",
    "\n",
    "\n",
    "**Latent variables**\n",
    "- $Z$: The latent topic assignments for each word\n",
    "- $\\theta$: Parameters for the document-topic distribution\n",
    "\n",
    "**Variational parameters**\n",
    "- $\\phi$: Parameters for the variational multinomial approximation to $z$\n",
    "- $\\gamma$: Parameters for the variational Dirichlet approximation to $\\theta$\n",
    "\n",
    "**Model parameters**\n",
    "- $\\alpha$: Parameters for the Dirichlet prior on $\\theta$\n",
    "- $\\beta$: Parameters for the multinomial topic-word distribution $W|Z$\n",
    "\n",
    "**Parameterizations**\n",
    "- $\\theta_d \\sim \\text{Dir}(\\alpha) $\n",
    "- $z | \\theta \\sim \\text{Multi}(\\theta_d)$\n",
    "- $w | z \\sim \\text{Multi}(\\beta_z)$\n",
    "\n",
    "\n",
    "- $p(z_{n} = t| \\theta_d) = \\theta_{d, \\ t}$\n",
    "- $p(w_n | z_n = t) = \\beta_{t, \\ w_{n}}$\n",
    "\n",
    "**Variational Approximations**\n",
    "- $q(z_n | \\phi) = \\text{Multi}(\\phi_{n})$\n",
    "- $q(\\theta | \\gamma) = \\text{Dir}(\\gamma)$\n",
    "\n",
    "\n",
    "#### Dimensions\n",
    "\n",
    "- $\\alpha$: $T \\times 1$\n",
    "- $\\beta$: $T \\times N$ \n",
    "- $\\theta$: $D \\times T$\n",
    "- $Z$: $D \\times T \\times N_d$\n",
    "- $\\phi$: $D \\times T \\times N_d$\n",
    "- $\\gamma$: $T \\times D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation Model\n",
    "\n",
    "<img src=\"images/lda.png\" alt=\"Smiley face\" width=\"70%\">\n",
    "\n",
    "$$\n",
    "P(W, Z, \\theta, \\phi) = \\prod_{d=1}^D p(\\theta_d) \\left[\\prod_{n=1}^{N_d} p(z_{dn} | \\theta_d) p(w_{dn} | z_{dn}, \\beta_{z_{dn}})\\right]\n",
    "$$\n",
    "---\n",
    "\n",
    "Here's pseudocode for the generative model:\n",
    "```\n",
    "For each document d,\n",
    "    Choose the topic distribution θ_d ~ Dirichlet(α)\n",
    "    For each of the N_d words:\n",
    "        Choose a topic z_n ~ Multinomial(θ_d)\n",
    "        Then choose a word w_n ~ Multinomial(β_z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Given a corpus of documents, we'd like to find the model parameters $\\alpha$ and $\\beta$ that maximize the marginal log likelihood of the observed data, integrating/summing over the latent variables $\\theta$ and $z$:\n",
    "\n",
    "$$ \\alpha^*, \\beta^* = \\arg \\max_{\\alpha, \\beta} \\log p(W | \\alpha, \\beta)$$\n",
    "\n",
    "The standard approach to doing this is to use the Expectation-Maximization algorithm. In this approach, we iterate between:\n",
    "\n",
    "- **E-Step**: Maximize the probability of the hidden variables, $\\theta$ and $z$, given the observed data and current values for the model parameters: $p(\\theta,z | W, \\alpha, \\beta)$. \n",
    "- **M-Step**: Using the estimates for the latent variables $\\theta$ and $z$ found during the E-step, maximize the posterior distribution with respect to the model parameters $\\alpha$ and $\\beta$.\n",
    "\n",
    "Unfortunately, computing the posterior over hidden variables, $p(\\theta,z | W, \\alpha, \\beta)$ in the E-step is intractable for the LDA model. As a result, we must use an approximation: $q(\\theta, z | \\gamma, \\phi)$. This approach is known as **variational EM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational EM\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Big Ideas</strong></br>\n",
    "<ol>\n",
    "   <li>We want to find an approximation, $q(\\theta, z |\\gamma, \\phi)$, that is as close as possible to (i.e., has the minimal KL divergence to) the true model posterior, $p(\\theta, Z|W,\\alpha,\\beta)$.</li>\n",
    "    <li>Minimizing the KL divergence between $q(\\theta, z |\\gamma, \\phi)$ and $p(\\theta, z | W, \\alpha, \\beta)$ is equivalent to finding the variational parameters, $\\phi$, and $\\gamma$ that <em>maximize</em> a lower bound $\\mathcal{L}(\\gamma, \\phi, \\alpha,\\beta)$ on the marginal likelihood, $p(w | \\alpha, \\beta)$.</li> \n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "In variational inference, we consider a simplified graphical model with variational parameters $\\gamma$ and $\\phi$ and minimize the KL Divergence between the variational approximation, $q(\\theta, z | \\gamma, \\phi)$ and the true posterior  $p(z, \\theta |W, \\alpha, \\beta)$ during the E-step. \n",
    "\n",
    "We select the variational approximation to provide us with a lower bound on the marginal log likelihood, $\\log p(W | \\alpha, \\beta)$. We can show that with the correct choice of lower bound, maximizing with respect to the variational parameters is equivalent to _minimizing_ the KL divergence between the variational lower bound and the model posterior, $p(\\theta, z | W, \\alpha, \\beta)$.  \n",
    "\n",
    "- **E-step**: Maximize the variational approximation to the model posterior with respect to the variational parameters: $$\\begin{align*}\n",
    "    \\gamma^{(t)}, \\phi^{(t)} &= \\arg \\min_{\\gamma, \\phi} \\mathbb{KL} \\left[ q(\\theta^{(t-1)}, z^{(t-1)} | \\gamma, \\phi) \\ || \\ p(\\theta, z | W, \\alpha^{(t-1)}, \\beta^{(t-1)}) \\right] \\\\\n",
    "    &= \\arg \\max_{\\gamma, \\phi} \\mathcal{L}(\\gamma, \\phi, \\alpha^{(t-1)}, \\beta^{(t-1)})\n",
    "\\end{align*}$$.\n",
    "- **M-step**: Maximize the variational approximation with respect to the model parameters, using the variational parameters identified during the E-step: $$ \\alpha^{(t)}, \\beta^{(t)} = \\arg \\max_{\\alpha, \\beta} \\mathcal{L}(\\gamma^{(t)}, \\phi^{(t)}, \\alpha, \\beta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving the variational bound\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Big Ideas</strong><br>\n",
    "The variational lower bound on the marginal log likelihood is \n",
    "\n",
    "$$\\mathcal{L}(\\gamma,\\phi, \\alpha,\\beta) = \\mathbb{E}_q[\\log p(\\theta | \\alpha)] + \\mathbb{E}_q[\\log p(z|\\theta)] + \\mathbb{E}_q[\\log p(w | z, \\beta)] - \\mathbb{E}_q[\\log q(\\theta, z)]$$\n",
    "\n",
    "Maximizing the lower\n",
    "bound with respect to $\\gamma$ and $\\phi$ is equivalent to minimizing the KL divergence between the\n",
    "variational approximation to the posterior and the true posterior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    \\log p(w | \\alpha, \\beta) &= \\log \\int \\sum_{t=1}^T p(w, \\theta, z=t | \\alpha, \\beta) d\\theta\\\\\n",
    "    &= \\log \\int \\sum_{t=1}^T \\frac{q(\\theta, z=t)}{q(\\theta, z=t)} p(w, \\theta, z=t | \\alpha, \\beta) d\\theta\\\\\n",
    "    &= \\log \\mathbb{E}_q \\left[ \\frac{p(w, \\theta, z | \\alpha, \\beta)}{q(\\theta, z)} \\right]\\\\\n",
    "    &\\geq \\mathbb{E}_q \\left[ \\log \\frac{p(w, \\theta, z | \\alpha, \\beta)}{q(\\theta, z)} \\right]\\\\\n",
    "    &=\\mathbb{E}_q [\\log p(w, \\theta, z | \\alpha, \\beta)] - \\mathbb{E}_q[\\log q(\\theta, z)]\\\\\n",
    "    &= \\mathbb{E}_q[\\log p(\\theta | \\alpha)] + \\mathbb{E}_q[\\log p(z|\\theta)] + \\mathbb{E}_q[\\log p(w | z, \\beta)] - \\mathbb{E}_q[\\log q(\\theta, z)]\n",
    "\\end{align*}\n",
    "\n",
    "Thus, we have that our variational lower bound on the marginal log likelihood is \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\gamma,\\phi, \\alpha,\\beta) = \\mathbb{E}_q[\\log p(\\theta | \\alpha)] + \\mathbb{E}_q[\\log p(z|\\theta)] + \\mathbb{E}_q[\\log p(w | z, \\beta)] - \\mathbb{E}_q[\\log q(\\theta, z)]\n",
    "$$\n",
    "---\n",
    "\n",
    "Further, we can show that the difference between $\\log p(w | \\alpha, \\beta)$ and $\\mathcal{L}(\\gamma,\\phi, \\alpha,\\beta)$ is exactly equal to $\\mathbb{KL}[q(\\theta, z|\\gamma, \\phi) \\ || \\ p(z, \\theta | w, \\alpha,\\beta)]$ (see EM algorithm notes for details). As a result, we have that maximizing the lower\n",
    "bound with respect to $\\gamma$ and $\\phi$ is equivalent to minimizing the KL divergence between the\n",
    "variational approximation to the posterior and the true posterior.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean field approximation\n",
    "One standard choice for the variational family, $q$, is the **mean field approximation**. Under this family, we assume the variational distribution $q$ over the latent variables $z$ and $\\theta$ factorizes into the product of independent  distributions, each controlled by separate variational paramters $\\gamma$ and $\\phi$:\n",
    "\n",
    "$$q(\\theta, Z|\\gamma,\\phi) = \\prod_D q(\\theta_d | \\gamma) \\prod_N q(z_{dn} | \\phi)$$\n",
    "\n",
    "For the LDA model, we'll use the following forms for the factored variational distributions:\n",
    "\n",
    "\\begin{align*}\n",
    "    q(z_n | \\phi) &= \\text{Multi}(\\phi_{n})\\\\\n",
    "    q(\\theta_d | \\gamma) &= \\text{Dir}(\\gamma)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding each term in $\\mathcal{L}$\n",
    "All expansions are relative to a given document, $d$. A few useful facts:\n",
    "\n",
    "$$\n",
    "\\text{Dir}(\\alpha) = \\frac{\\Gamma\\left( \\sum_{i=1}^K \\alpha_i \\right)}{\\prod_{i=1}^K \\Gamma(\\alpha_i)} \\prod_{i=1}^K x_i^{\\alpha_i - 1}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{For }&X \\sim \\text{Dir}(\\gamma)\\\\\n",
    "    \\mathbb{E}[\\log X_i] &= \\Psi(\\gamma_i) - \\Psi(\\sum_k \\gamma_k)\n",
    "\\end{align}\n",
    "\n",
    "where $\\Psi$ is the [digamma function](https://en.wikipedia.org/wiki/Digamma_function):\n",
    "\n",
    "$$\n",
    "\\Psi(x) = \\frac{\\Gamma'(x)}{\\Gamma(x)} = \\frac{d}{dx} \\log \\Gamma(x)\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}_q[\\log p(\\theta | \\alpha)] &= \\int \\sum_z q(\\theta, z| \\gamma, \\phi) \\log \\text{Dir}(\\alpha) \\ d\\theta \\\\\n",
    "&= \\int \\sum_z q(\\theta, z| \\gamma, \\phi) \\log \\left[ \\frac{\\Gamma(\\sum_{t=1}^T \\alpha_t)}{\\prod_{t=1}^T \\Gamma(\\alpha_t)} \\prod_{t=1}^T \\theta_t^{(\\alpha_t - 1)} \\right] \\ d\\theta\\\\\n",
    "&= \\int \\sum_z q(\\theta, z| \\gamma, \\phi) \\left[\\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\log \\theta_t \\right] \\ d\\theta\\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\int \\sum_z q(\\theta, z| \\gamma, \\phi) \\sum_{t=1}^T (\\alpha_t - 1) \\log \\theta_t \\ d\\theta \\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\int \\sum_z q(\\theta, z| \\gamma, \\phi) \\log \\theta_t \\ d\\theta \\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\int q(\\theta| \\gamma)  \\log \\theta_t \\sum_z q(z|\\phi) \\ d\\theta \\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\int q(\\theta| \\gamma)  \\log \\theta_t \\ d\\theta\\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\mathbb{E}_q[\\log \\theta_t] \\\\\n",
    "&= \\log \\Gamma(\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) + \\sum_{t=1}^T (\\alpha_t - 1) \\left(\\Psi(\\gamma_t) - \\Psi( \\sum_{t=1}^T \\gamma_t)\\right)\n",
    "\\end{align*}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}_q[\\log p(z=t|\\theta)] &= \\int \\sum_z q(\\theta, z) \\log p(z | \\theta) \\ d\\theta \\\\\n",
    "&= \\int \\sum_{z} q(\\theta, z) \\sum_{n=1}^{N_d} \\sum_{t=1}^T \\log p(z_n = t | \\theta) \\ d\\theta \\\\\n",
    "&= \\int \\sum_{z} q(\\theta, z)\\sum_{n=1}^{N_d} \\sum_{t=1}^T [z_n = t] \\log \\theta_{t} \\ d\\theta \\\\\n",
    "&= \\mathbb{E}_q \\left[\\sum_{n=1}^{N_d} \\sum_{t=1}^T [z_n = t] \\log \\theta_t \\right]\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\sum_{t=1}^T \\mathbb{E}_q \\left[ [z_n = t] \\log \\theta_t \\right] &&\\text{By linearity of expectation}\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\sum_{t=1}^T \\mathbb{E}_{q(z)} \\left[ z_n = t \\right] \\mathbb{E}_{q(\\theta)}\\left[ \\log \\theta_t \\right] &&\\text{$q(z)$ and $q(\\theta)$ are independent under mean field approx.}\\\\\n",
    "&= \\sum_{n-1}^{N_d} \\sum_{t=1}^T \\phi_{t, n} \\left( \\Psi(\\gamma_t) - \\Psi(\\sum_k \\gamma_k) \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_q [\\log p(w | z, \\beta) ] &= \\int \\sum_z q(z, \\theta) \\log p(w | z, \\beta) \\ d\\theta\\\\\n",
    "&= \\int \\sum_z q(z, \\theta) \\sum_{n=1}^{N_d} \\log p(w_n | z_n, \\beta) \\ d\\theta\\\\\n",
    "&= \\int \\sum_z q(z, \\theta) \\sum_{n=1}^{N_d} [z_n = t] \\log \\beta_{t, \\ w_{n}} \\ d\\theta\\\\\n",
    "&= \\mathbb{E}_q \\left[ \\sum_{n=1}^{N_d} [z_n = t] \\log \\beta_{t, \\ w_n} \\right]\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\mathbb{E}_q [ [z_n = t] \\log \\beta_{t, \\ w_n} ]\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\mathbb{E}_q [ z_n = t ] \\mathbb{E}_q [\\log \\beta_{t, \\ w_n} ]\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\phi_{t, n} \\mathbb{E}_q [\\log \\beta_{t, \\ w_n} ]\\\\\n",
    "&= \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\beta_{t, \\ w_n} &&\\text{Since $\\beta_{t, \\ w_n}$ doesn't depend on $\\theta$ or $z$}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_q [ \\log q(\\theta, z) ] &= \\mathbb{E}_q [\\log q(\\theta) + \\log q(z) ] \\\\\n",
    "&= \\mathbb{E}_{q(\\theta)} [ \\log q(\\theta) ] + \\mathbb{E}_{q(z)} [ \\log q(z)] &&\\text{By linearity of expectation}\\\\\n",
    "&= \\int q(\\theta) \\log q(\\theta) \\ d\\theta + \\sum_z q(z) \\log q(z)\\\\\n",
    "&= \\int q(\\theta) \\log \\text{Dir}(\\gamma) \\ d\\theta + \\sum_z q(z) \\log \\text{Dir}(\\phi)\\\\\n",
    "&= \\int q(\\theta) \\left[ \\log \\Gamma \\left(\\sum_{i=1}^T \\gamma_i \\right) - \\sum_{i=1}^T \\log \\Gamma(\\gamma_i) + \\sum_{i=1}^T (\\gamma_i - 1) \\log \\theta_i  \\right]\\  d\\theta + \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n}\\\\\n",
    "&= \\log \\Gamma \\left(\\sum_{i=1}^T \\gamma_i \\right) - \\sum_{i=1}^T \\log \\Gamma(\\gamma_i) + \\sum_{i=1}^T (\\gamma_i - 1) \\int q(\\theta) \\log \\theta_i \\  d\\theta + \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n}\\\\\n",
    "&= \\log \\Gamma \\left(\\sum_{i=1}^T \\gamma_i \\right) - \\sum_{i=1}^T \\log \\Gamma(\\gamma_i) + \\sum_{i=1}^T (\\gamma_i - 1) \\mathbb{E}_q[ \\log \\theta_i ] + \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n}\\\\\n",
    "&= \\log \\Gamma \\left(\\sum_{i=1}^T \\gamma_i \\right) - \\sum_{i=1}^T \\log \\Gamma(\\gamma_i) + \\sum_{i=1}^T (\\gamma_i - 1) \\left( \\Psi(\\gamma_i) - \\Psi(\\sum_k \\gamma_k) \\right) + \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-Step\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Big Ideas</strong><br>\n",
    "The updates to the variational parameters during the E-step are:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\phi_{t, n} &\\propto \\beta_{t, \\ w_n} \\exp \\left\\{ \\Psi(\\gamma_t) \\right\\}\\\\\n",
    "    \\gamma_t &= \\alpha_t + \\sum_{n=1}^{N_d} \\phi_{t, n}    \n",
    "\\end{align}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the E-step, we are interested in maximizing our lower bound $\\mathcal{L}$ with respect to the variational parameters, $\\gamma$ and $\\phi$:\n",
    "\n",
    "$$\n",
    "\\gamma^*, \\phi^* = \\arg \\max_{\\gamma, \\phi} \\mathcal{L}(\\gamma, \\phi, \\alpha^{(t-1)}, \\beta^{(t-1)})\n",
    "$$\n",
    "\n",
    "Now that we've written out each term of $\\mathcal{L}$ for the LDA model, we can go about differentiating with respect to $\\phi$ and $\\gamma$, setting each to 0, and solving for the optimal paramters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for $\\phi$\n",
    "Begin by writing out the components of $\\mathcal{L}$ that depend on $\\phi$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}_\\phi &=  \\sum_{n-1}^{N_d} \\sum_{t=1}^T \\phi_{t, n} \\left( \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) \\right) + \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\beta_{t, \\ w_n} - \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Note that $\\phi$ represents probabilities such that $\\sum_{t = 1}^T \\phi_{t, n} = 1$. Because of this constraint, we will use Lagrange multipliers, introducing a constraint term with weight $\\lambda_n$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}_\\phi &=  \\sum_{n-1}^{N_d} \\sum_{t=1}^T \\phi_{t, n} \\left( \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) \\right) + \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\beta_{t, \\ w_n} - \\sum_{t=1}^T \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\phi_{t, n} + \\lambda_n \\left( \\sum_{t=1}^T \\phi_{t, n} - 1 \\right)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now we differentiate with respect to $\\phi_{t, n}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\phi_{t, n}} &= \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) + \\log \\beta_{t, \\ w_n} - \\log \\phi_{t, n} - 1 + \\lambda_n\n",
    "\\end{align*}\n",
    "and set this term to 0:\n",
    "\n",
    "\\begin{align*}\n",
    "0 &= \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) + \\log \\beta_{t, \\ w_n} - \\log \\phi_{t, n} - 1 + \\lambda_n\\\\\n",
    "\\log \\phi_{t, n} &= \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) + \\log \\beta_{t, \\ w_n} - 1 + \\lambda_n\\\\\n",
    "\\phi_{t, n} &= \\exp \\left\\{ \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) + \\log \\beta_{t, \\ w_n} - 1 + \\lambda_n \\right\\}\\\\\n",
    "\\phi_{t, n} &= \\beta_{t, \\ w_n} \\exp \\left\\{ \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) - 1 + \\lambda_n \\right\\}\\\\\n",
    "\\phi_{t, n} &= \\beta_{t, \\ w_n} \\frac{\\exp \\left\\{ \\Psi(\\gamma_t) + \\lambda_n \\right\\} }{\\exp \\left\\{1 +  \\Psi(\\sum_T \\gamma_t) \\right\\}}\\\\\n",
    "\\phi_{t, n} &\\propto \\beta_{t, \\ w_n} \\exp \\left\\{ \\Psi(\\gamma_t) + \\lambda_n \\right\\}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Note that $\\lambda_n$ is constant for all topics $t$, and thus we can absorb it into the proportionality constant when computing $\\phi_{t, n}$. Hence we have\n",
    "\n",
    "$$\\phi_{t, n} \\propto \\beta_{t, \\ w_n} \\exp \\left\\{ \\Psi(\\gamma_t) \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for $\\gamma$\n",
    "Begin by writing out the components of $\\mathcal{L}$ that depend on $\\gamma$:\n",
    "\n",
    "$$ \n",
    "    \\mathcal{L}_\\gamma = \\sum_{t=1}^T (\\alpha_t - 1) \\left(\\Psi(\\gamma_t) - \\Psi(\\sum_{t=1}^T \\gamma_t)\\right) + \\sum_{n=1}^{N_d} \\sum_{t=1}^T \\phi_{t, n} \\left( \\Psi(\\gamma_t) - \\Psi( \\sum_k \\gamma_k) \\right) - \\log \\Gamma \\left(\\sum_{i=1}^T \\gamma_i \\right) + \\sum_{t=1}^T \\log \\Gamma(\\gamma_t) - \\sum_{t=1}^T (\\gamma_t - 1) \\left( \\Psi(\\gamma_t) - \\Psi(\\sum_T \\gamma_t) \\right)\n",
    "$$\n",
    "\n",
    "Now we differentiate with respect to $\\gamma_{t}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\gamma_t} &= (\\alpha_t - 1) \\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right) + \\sum_{n=1}^{N_d} \\phi_{t, n}\\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right) - \\Psi(\\sum_{i=1}^T \\gamma_i) + \\Psi(\\gamma_t) - (\\gamma_t - 1) \\left( \\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t) \\right) - \\Psi(\\gamma_t) + \\Psi(\\sum_T \\gamma_t)\\\\\n",
    "    &= (\\alpha_t - 1) \\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right) + \\sum_{n=1}^{N_d} \\phi_{t, n}\\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right)- (\\gamma_t - 1) \\left( \\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t) \\right) \\\\\n",
    "    &= \\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right) \\left[ (\\alpha_t - 1) + \\sum_{n=1}^{N_d} \\phi_{t, n} - (\\gamma_t - 1) \\right]\n",
    "\\end{align*}\n",
    "\n",
    "and set this expression to 0:\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= \\left(\\Psi'(\\gamma_t) - \\Psi'(\\sum_T \\gamma_t)\\right) \\left[ (\\alpha_t - 1) + \\sum_{n=1}^{N_d} \\phi_{t, n} - (\\gamma_t - 1) \\right]\\\\\n",
    "\\end{align*}\n",
    "\n",
    "We'll focus on the expression on the right hand side:\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= (\\alpha_t - 1) + \\sum_{n=1}^{N_d} \\phi_{t, n} - (\\gamma_t - 1)\\\\\n",
    "    &= \\alpha_t - \\gamma_t + \\sum_{n=1}^{N_d} \\phi_{t, n}\\\\\n",
    "    \\gamma_t &= \\alpha_t + \\sum_{n=1}^{N_d} \\phi_{t, n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## M-Step\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Big Ideas</strong><br>\n",
    "The updates to the model parameters during the M-step are:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "     \\beta_{t, n}^* &\\propto \\sum_{d=1}^D \\sum_{i=1}^{N_d}\\phi_{d, t, n} [ i = n] \\\\\n",
    "     \\alpha_{t} &= \\text{No closed form expression. Use Newton-Raphson}\n",
    "\\end{align}\n",
    "\n",
    "</div>\n",
    "\n",
    "During the M-step, we are interested in maximizing our lower bound $\\mathcal{L}$ with respect to the model parameters, $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$\n",
    "\\alpha^*, \\beta^* = \\arg \\max_{\\alpha, \\beta} \\mathcal{L}(\\gamma^{(t)}, \\phi^{(t)}, \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "where $\\gamma^{(t)}$ and $\\phi^{(t)}$ are the variational parameters identified during the E-step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for $\\beta$\n",
    "\n",
    "Begin by writing out the components of $\\mathcal{L}$ that depend on $\\beta$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\beta = \\sum_{n=1}^{N_d} \\phi_{t, n} \\log \\beta_{t, \\ w_n}\n",
    "$$\n",
    "\n",
    "Note that $\\beta$ is a probability distribution and we have that $\\sum_{n=1}^{N_d} \\beta_{t, \\ n} = 1$. As a result, we incorporate Lagrange multipliers with weights $\\rho$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\beta = \\sum_{d=1}^D \\sum_{n=1}^{N_d} \\phi_{d, t, n} \\log \\beta_{t, \\ n} + \\sum_{t=1}^T \\rho_t \\sum_{n=1}^{N_d} \\beta_{t, \\ n} - 1\n",
    "$$\n",
    "\n",
    "Differentiating with respect to $\\beta_{t, n}$ gives us:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\beta_{t, n}} &=  \\frac{\\sum_{d=1}^D \\sum_{i=1}^{N_d}\\phi_{d, t, n} [ i = n]}{\\beta_{t,n}} + \\rho_t\n",
    "\\end{align*}\n",
    "Setting this to 0 and solving for $\\rho_t$ yields:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\rho_i = −\\sum_{d, t, i} \\phi_{d, t, n} [ i = n]\n",
    "\\end{align*}\n",
    "\n",
    "However, because we know that $\\sum_{n=1}^{N_d} \\beta_{t, \\ n} = 1$, we can ignore $\\rho_i$ and calculate the unnormalized expression for $\\beta_{t, n}^*$:\n",
    "\n",
    "$$\n",
    "\\beta_{t, n}^* \\propto \\sum_{d=1}^D \\sum_{i=1}^{N_d}\\phi_{d, t, n} [ i = n]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for $\\alpha$\n",
    "\n",
    "Begin by writing out the components of $\\mathcal{L}$ that depend on $\\alpha$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\alpha = \\sum_{d=1}^D \\left( \\sum_{t=1}^T (\\alpha_t - 1)(\\Psi(\\gamma_{d, t} ) - \\Psi(\\sum_{t=1}^T \\gamma_{d, t} ) ) + \\log \\Gamma (\\sum_{t=1}^T \\alpha_t) - \\sum_{t=1}^T \\log \\Gamma(\\alpha_t) \\right)\n",
    "$$\n",
    "\n",
    "Differentiating with respect to $\\alpha_t$ yields:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\alpha_t} &= \\sum_{d=1}^D \\left(\\Psi(\\gamma_{d, t} ) - \\Psi(\\sum_{t=1}^T \\gamma_{d, t} ) \\right) + D \\left( \\Psi(\\sum_{t=1}^T \\alpha_t) - \\Psi(\\alpha_t) \\right)\n",
    "\\end{align*}\n",
    "\n",
    "Unfortunately, this derivative indicates that the optimal value for $\\alpha_t$ depends on the values of the other $\\alpha_j$ for $j \\neq t$. Blei et al. propose an iterative method to maximize $\\alpha_t$ based on the [Newton-Raphson algorithm](https://en.wikipedia.org/wiki/Newton%27s_method), noting that because the Hessian of the above expression is a matrix of the form:\n",
    "\n",
    "$$\n",
    "H = \\text{diag}(h) + \\mathbf{1}z\\mathbf{1}^\\top\n",
    "$$\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "    h &= -D \\Psi'(\\alpha)\\\\\n",
    "    z &= D \\Psi'(\\sum_{t=1}^T \\alpha_t )\n",
    "\\end{align*}\n",
    "\n",
    "its inverse can be written as\n",
    "\n",
    "$$\n",
    "H^{-1} = \\text{diag}(h)^{-1} = \\frac{\\text{diag}(h)^{-1} \\mathbf{11}^\\top \\text{diag}(h)^{-1}}{z^{-1} \\sum_{t=1}^{T}h_t^{-1}}\n",
    "$$\n",
    "\n",
    "and we can compute the stable point for $\\alpha_t$ using $O(n)$ operations rather than the traditional $O(n^3)$ required when inverting Hessians in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma, polygamma, gammaln\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dg(gamma, d, t):\n",
    "    \"\"\"\n",
    "    E[log X_t] where X_t ~ Dir\n",
    "    \"\"\"\n",
    "    return digamma(gamma[d, t]) - digamma(np.sum(gamma[d, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we generate a fake dataset for validating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8675309)\n",
    "\n",
    "# Generate some fake data\n",
    "D = 300\n",
    "T = 10\n",
    "V = 30\n",
    "N = np.random.randint(150, 200, size=D)\n",
    "\n",
    "# Create a document-topic distribution for 3 different types of documents\n",
    "alpha1 = np.array((20, 15, 10, 1, 1, 1, 1, 1, 1, 1))\n",
    "alpha2 = np.array((1, 1, 1, 10, 15, 20, 1, 1, 1, 1))\n",
    "alpha3 = np.array((1, 1, 1, 1, 1, 1, 10, 12, 15, 18))\n",
    "\n",
    "# Arbitrarily choose each topic to have 3 very common, diagnostic words\n",
    "# These words are barely shared with any other topic\n",
    "beta_probs = np.ones((V, T)) + np.array([np.arange(V) % T == t for t in range(T)]).T * 19\n",
    "beta_gen = np.array(list(map(lambda x: np.random.dirichlet(x), beta_probs.T))).T\n",
    "\n",
    "corpus = []\n",
    "theta = np.empty((D, T))\n",
    "\n",
    "# Generate each document from the LDA model\n",
    "for d in range(D):\n",
    "    \n",
    "    # Draw topic distribution for the document\n",
    "    if d < (D / 3):\n",
    "        theta[d, :] = np.random.dirichlet(alpha1, 1)[0]\n",
    "    elif d < 2 * (D / 3):\n",
    "        theta[d, :] = np.random.dirichlet(alpha2, 1)[0]\n",
    "    else:\n",
    "        theta[d, :] = np.random.dirichlet(alpha3, 1)[0]\n",
    "        \n",
    "    doc = np.array([])\n",
    "    for n in range(N[d]):\n",
    "        # Draw a topic according to the document's topic distribution\n",
    "        z_n = np.random.choice(np.arange(T), p=theta[d, :])\n",
    "        \n",
    "        # Draw a word according to the topic-word distribution\n",
    "        w_n = np.random.choice(np.arange(V), p=beta_gen[:, z_n])\n",
    "        doc = np.append(doc, w_n)\n",
    "        \n",
    "    corpus.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA(object):\n",
    "    \"\"\"\n",
    "    Vanilla (non-smoothed) LDA model trained using variational EM.\n",
    "    Generates maximum-likelihood estimates for model paramters \n",
    "    `alpha` and `beta`.\n",
    "    \n",
    "    T : int\n",
    "        Number of topics\n",
    "        \n",
    "    D : int\n",
    "        Number of documents\n",
    "        \n",
    "    N : int\n",
    "        Number of words in each document\n",
    "        \n",
    "    V : int\n",
    "        Number of unique word tokens across all documents\n",
    "    \n",
    "    phi : array of shape D x N[d] x T\n",
    "        Variational approximation to word-topic distribution\n",
    "        \n",
    "    gamma : array of shape D x T\n",
    "        Variational approximation to document-topic distribution\n",
    "        \n",
    "    alpha : array of shape 1 x T\n",
    "        Parameter for the Dirichlet prior on the document-topic distribution\n",
    "        \n",
    "    beta  : array of shape V x T\n",
    "        Word-topic distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, T=10):\n",
    "        self.T = T\n",
    "    \n",
    "    def _maximize_phi(self):\n",
    "        \"\"\"\n",
    "        Optimize variational parameter phi\n",
    "        ϕ_{t, n} ∝ β_{t, w_n}  e^( Ψ(γ_t) )\n",
    "        \"\"\"\n",
    "        D = self.D\n",
    "        N = self.N\n",
    "        T = self.T\n",
    "        \n",
    "        phi   = self.phi\n",
    "        beta  = self.beta\n",
    "        gamma = self.gamma\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        for d in range(D):\n",
    "            for n in range(N[d]):\n",
    "                for t in range(T):\n",
    "                    w_n = int(corpus[d][n])\n",
    "                    phi[d][n, t] = beta[w_n, t] * np.exp(dg(gamma, d, t))\n",
    "\n",
    "                # Normalize over topics\n",
    "                phi[d][n, :] = phi[d][n, :] / np.sum(phi[d][n, :])\n",
    "        return phi\n",
    "\n",
    "    def _maximize_gamma(self):\n",
    "        \"\"\"\n",
    "        Optimize variational parameter gamma\n",
    "        γ_t = α_t + \\sum_{n=1}^{N_d} ϕ_{t, n}    \n",
    "        \"\"\"\n",
    "        D = self.D\n",
    "        phi   = self.phi\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        gamma = np.tile(alpha, (D, 1)) + np.array(list(map(lambda x: np.sum(x, axis=0), phi)))\n",
    "        return gamma\n",
    "\n",
    "    def _maximize_beta(self):\n",
    "        \"\"\"\n",
    "        Optimize model parameter beta\n",
    "        β_{t, n} ∝ \\sum_{d=1}^D \\sum_{i=1}^{N_d} ϕ_{d, t, n} [ i = n]\n",
    "        \"\"\"\n",
    "        T = self.T\n",
    "        V = self.V\n",
    "\n",
    "        phi    = self.phi\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        for n in range(V):\n",
    "            # Construct binary mask [i == n] to be the same shape as phi\n",
    "            mask = [np.tile((doc == n), (T, 1)).T for doc in corpus]\n",
    "            beta[n, :] = np.sum(np.array(list(map(lambda x: np.sum(x, axis=0), phi * mask))), axis=0)\n",
    "\n",
    "        # Normalize over words\n",
    "        for t in range(T):\n",
    "            beta[:, t] = beta[:, t] / np.sum(beta[:, t])\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def _maximize_alpha(self, max_iters=1000, tol=0.1):\n",
    "        \"\"\"\n",
    "        Optimize alpha using Blei's O(n) Newton-Raphson modification \n",
    "        for a Hessian with special structure\n",
    "        \"\"\"\n",
    "        D = self.D\n",
    "        T = self.T\n",
    "        \n",
    "        alpha = self.alpha\n",
    "        gamma = self.gamma\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "            alpha_old = alpha\n",
    "\n",
    "            #  Calculate gradient \n",
    "            g = D * (digamma(np.sum(alpha)) - digamma(alpha)) + \\\n",
    "                np.sum(digamma(gamma) - np.tile(digamma(np.sum(gamma, axis=1)), (T, 1)).T, axis=0)\n",
    "\n",
    "            #  Calculate Hessian diagonal component\n",
    "            h = -D * polygamma(1, alpha)\n",
    "\n",
    "            #  Calculate Hessian constant component\n",
    "            z = D * polygamma(1, np.sum(alpha))\n",
    "\n",
    "            #  Calculate constant\n",
    "            c = np.sum(g / h) / (z**(-1.0) + np.sum(h**(-1.0)))\n",
    "\n",
    "            #  Update alpha\n",
    "            alpha = alpha - (g - c) / h\n",
    "\n",
    "            #  Check convergence\n",
    "            if np.sqrt(np.mean(np.square(alpha - alpha_old))) < tol:\n",
    "                break\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def _E_step(self):\n",
    "        \"\"\"\n",
    "        Maximize the VLB with respect to the variational parameters, γ and ϕ\n",
    "        \"\"\"\n",
    "        self.phi   = self._maximize_phi()\n",
    "        self.gamma = self._maximize_gamma()\n",
    "    \n",
    "    def _M_step(self):\n",
    "        \"\"\"\n",
    "        Maximize the VLB with respect to the model parameters, α and β\n",
    "        \"\"\"\n",
    "        self.beta  = self._maximize_beta()\n",
    "        self.alpha = self._maximize_alpha()\n",
    "        \n",
    "    def VLB(self):\n",
    "        \"\"\"\n",
    "        Variational lower bound\n",
    "        \"\"\"\n",
    "        phi    = self.phi\n",
    "        alpha  = self.alpha\n",
    "        beta   = self.beta\n",
    "        gamma  = self.gamma\n",
    "        corpus = self.corpus\n",
    "       \n",
    "        D = self.D\n",
    "        T = self.T\n",
    "        N = self.N\n",
    "        \n",
    "        a, b, c, _d = 0, 0, 0, 0\n",
    "        for d in range(D):\n",
    "            a += gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + \\\n",
    "                np.sum([(alpha[t] - 1) * dg(gamma, d, t) for t in range(T)])\n",
    "            \n",
    "            _d += gammaln(np.sum(gamma[d, :])) - np.sum(gammaln(gamma[d, :])) + \\\n",
    "                np.sum([(gamma[d, t] - 1) * dg(gamma, d, t) for t in range(T)])\n",
    "                \n",
    "            for n in range(N[d]):\n",
    "                w_n = int(corpus[d][n])\n",
    "                \n",
    "                b += np.sum([phi[d][n, t] * dg(gamma, d, t) for t in range(T)])\n",
    "                c += np.sum([phi[d][n, t] * np.log(beta[w_n, t]) for t in range(T)])\n",
    "                _d += np.sum([phi[d][n, t] * np.log(phi[d][n, t]) for t in range(T)])\n",
    "                \n",
    "        return a + b + c - _d\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Provide reasonable initializations for model and variational parameters\n",
    "        \"\"\"\n",
    "        T = self.T\n",
    "        V = self.V\n",
    "        N = self.N\n",
    "        D = self.D\n",
    "                \n",
    "        # initialize model parameters\n",
    "        self.alpha = 100 * np.random.dirichlet(10 * np.ones(T), 1)[0]\n",
    "        self.beta = np.random.dirichlet(np.ones(V), T).T\n",
    "\n",
    "        # initialize variational parameters\n",
    "        self.phi = np.array([1 / T * np.ones([N[d], T]) for d in range(D)])\n",
    "        self.gamma = np.tile(alpha, (D, 1)) + np.tile(N / T, (T, 1)).T        \n",
    "    \n",
    "    def train(self, corpus, verbose=False, max_iter=1000, tol=5):\n",
    "        \"\"\"\n",
    "        Train the LDA model on a corpus of documents (bags of words).\n",
    "        \"\"\"\n",
    "        self.D = len(corpus)\n",
    "        self.V = len(set(np.concatenate(corpus)))\n",
    "        self.N = np.array([len(d) for d in corpus])\n",
    "        self.corpus = corpus\n",
    "\n",
    "        self.initialize_parameters()\n",
    "        vlb = -np.inf\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            old_vlb = vlb\n",
    "            \n",
    "            self._E_step()\n",
    "            self._M_step()\n",
    "            \n",
    "            vlb = self.VLB()\n",
    "            delta = vlb - old_vlb\n",
    "            \n",
    "            if verbose:\n",
    "                print('Iteration {}: {:.3f} (delta: {:.2f})'\n",
    "                      .format(i + 1, vlb, delta))\n",
    "                \n",
    "            if delta < tol:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: -178732.015 (delta: inf)\n",
      "Iteration 2: -177905.947 (delta: 826.07)\n",
      "Iteration 3: -177770.789 (delta: 135.16)\n",
      "Iteration 4: -177660.543 (delta: 110.25)\n",
      "Iteration 5: -177552.810 (delta: 107.73)\n",
      "Iteration 6: -177430.731 (delta: 122.08)\n",
      "Iteration 7: -177272.880 (delta: 157.85)\n",
      "Iteration 8: -177046.321 (delta: 226.56)\n",
      "Iteration 9: -176697.542 (delta: 348.78)\n",
      "Iteration 10: -176146.280 (delta: 551.26)\n",
      "Iteration 11: -175302.602 (delta: 843.68)\n",
      "Iteration 12: -174134.059 (delta: 1168.54)\n",
      "Iteration 13: -172738.643 (delta: 1395.42)\n",
      "Iteration 14: -171276.804 (delta: 1461.84)\n",
      "Iteration 15: -169796.186 (delta: 1480.62)\n",
      "Iteration 16: -168306.251 (delta: 1489.94)\n",
      "Iteration 17: -166995.883 (delta: 1310.37)\n",
      "Iteration 18: -166074.624 (delta: 921.26)\n",
      "Iteration 19: -165527.052 (delta: 547.57)\n",
      "Iteration 20: -165214.430 (delta: 312.62)\n",
      "Iteration 21: -165029.100 (delta: 185.33)\n",
      "Iteration 22: -164911.572 (delta: 117.53)\n",
      "Iteration 23: -164830.596 (delta: 80.98)\n",
      "Iteration 24: -164770.595 (delta: 60.00)\n",
      "Iteration 25: -164723.589 (delta: 47.01)\n",
      "Iteration 26: -164685.210 (delta: 38.38)\n",
      "Iteration 27: -164652.865 (delta: 32.34)\n",
      "Iteration 28: -164624.900 (delta: 27.97)\n",
      "Iteration 29: -164600.202 (delta: 24.70)\n",
      "Iteration 30: -164577.996 (delta: 22.21)\n",
      "Iteration 31: -164557.730 (delta: 20.27)\n",
      "Iteration 32: -164538.999 (delta: 18.73)\n",
      "Iteration 33: -164521.508 (delta: 17.49)\n",
      "Iteration 34: -164505.035 (delta: 16.47)\n",
      "Iteration 35: -164489.409 (delta: 15.63)\n",
      "Iteration 36: -164474.501 (delta: 14.91)\n",
      "Iteration 37: -164460.210 (delta: 14.29)\n",
      "Iteration 38: -164446.453 (delta: 13.76)\n",
      "Iteration 39: -164433.165 (delta: 13.29)\n",
      "Iteration 40: -164420.291 (delta: 12.87)\n",
      "Iteration 41: -164407.782 (delta: 12.51)\n",
      "Iteration 42: -164395.599 (delta: 12.18)\n",
      "Iteration 43: -164383.705 (delta: 11.89)\n",
      "Iteration 44: -164372.067 (delta: 11.64)\n",
      "Iteration 45: -164360.655 (delta: 11.41)\n",
      "Iteration 46: -164349.442 (delta: 11.21)\n",
      "Iteration 47: -164338.404 (delta: 11.04)\n",
      "Iteration 48: -164327.518 (delta: 10.89)\n",
      "Iteration 49: -164316.765 (delta: 10.75)\n",
      "Iteration 50: -164306.128 (delta: 10.64)\n",
      "Iteration 51: -164295.593 (delta: 10.53)\n",
      "Iteration 52: -164285.150 (delta: 10.44)\n",
      "Iteration 53: -164274.789 (delta: 10.36)\n",
      "Iteration 54: -164264.508 (delta: 10.28)\n",
      "Iteration 55: -164254.302 (delta: 10.21)\n",
      "Iteration 56: -164244.175 (delta: 10.13)\n",
      "Iteration 57: -164234.129 (delta: 10.05)\n",
      "Iteration 58: -164224.169 (delta: 9.96)\n",
      "Iteration 59: -164214.305 (delta: 9.86)\n",
      "Iteration 60: -164204.543 (delta: 9.76)\n",
      "Iteration 61: -164194.892 (delta: 9.65)\n",
      "Iteration 62: -164185.363 (delta: 9.53)\n",
      "Iteration 63: -164175.963 (delta: 9.40)\n",
      "Iteration 64: -164166.699 (delta: 9.26)\n",
      "Iteration 65: -164157.579 (delta: 9.12)\n",
      "Iteration 66: -164148.608 (delta: 8.97)\n",
      "Iteration 67: -164139.790 (delta: 8.82)\n",
      "Iteration 68: -164131.128 (delta: 8.66)\n",
      "Iteration 69: -164122.625 (delta: 8.50)\n",
      "Iteration 70: -164114.280 (delta: 8.34)\n",
      "Iteration 71: -164106.096 (delta: 8.18)\n",
      "Iteration 72: -164098.070 (delta: 8.03)\n",
      "Iteration 73: -164090.202 (delta: 7.87)\n",
      "Iteration 74: -164082.493 (delta: 7.71)\n",
      "Iteration 75: -164074.939 (delta: 7.55)\n",
      "Iteration 76: -164067.539 (delta: 7.40)\n",
      "Iteration 77: -164060.293 (delta: 7.25)\n",
      "Iteration 78: -164053.197 (delta: 7.10)\n",
      "Iteration 79: -164046.250 (delta: 6.95)\n",
      "Iteration 80: -164039.450 (delta: 6.80)\n",
      "Iteration 81: -164032.794 (delta: 6.66)\n",
      "Iteration 82: -164026.280 (delta: 6.51)\n",
      "Iteration 83: -164019.906 (delta: 6.37)\n",
      "Iteration 84: -164013.669 (delta: 6.24)\n",
      "Iteration 85: -164007.566 (delta: 6.10)\n",
      "Iteration 86: -164001.595 (delta: 5.97)\n",
      "Iteration 87: -163995.753 (delta: 5.84)\n",
      "Iteration 88: -163990.037 (delta: 5.72)\n",
      "Iteration 89: -163984.445 (delta: 5.59)\n",
      "Iteration 90: -163978.974 (delta: 5.47)\n",
      "Iteration 91: -163973.621 (delta: 5.35)\n",
      "Iteration 92: -163968.383 (delta: 5.24)\n",
      "Iteration 93: -163963.258 (delta: 5.13)\n",
      "Iteration 94: -163958.242 (delta: 5.02)\n",
      "Iteration 95: -163953.333 (delta: 4.91)\n"
     ]
    }
   ],
   "source": [
    "L = LDA(10)\n",
    "L.train(corpus, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Beta')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c4aae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(L.beta)\n",
    "ax.set_xlabel('Topics')\n",
    "ax.set_ylabel('Words')\n",
    "ax.set_title('Beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Gamma')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c599320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(L.gamma)\n",
    "ax.set_xlabel('Topics')\n",
    "ax.set_ylabel('Document')\n",
    "ax.set_title('Gamma')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
